{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Model Languages\n",
    "\n",
    "Tarea 3 - Luis Eduardo Robles Jimenez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dict()\n",
    "tokens['begin'], tokens['end'], tokens['unknown'] = '<s>', '</s>', '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_vocabulary(corpus, size):                           # Returns words sorted by frequency\n",
    "    words, tokenizer, corpusByWords = [], TweetTokenizer(), []\n",
    "    for doc in corpus:\n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        words += tokens\n",
    "        corpusByWords += [tokens]\n",
    "    count = nltk.FreqDist(words)\n",
    "    count = sorted([(count[key], key) for key in count])[::-1]\n",
    "    if size != -1: count = count[:size]\n",
    "    return [word for _, word in count], corpusByWords\n",
    "\n",
    "def load_corpus(corpus_select = \"tweets\", vocabSize = 100):\n",
    "    corpus = []\n",
    "    path_corpus = \"../../data/agresividad/mex_train.txt\"\n",
    "\n",
    "    with open(path_corpus, \"r\") as f_corpus:\n",
    "        for tuit in f_corpus:\n",
    "            corpus += [tuit[:-1]]\n",
    "    \n",
    "    vocab, tokenized = _create_vocabulary(corpus, vocabSize)\n",
    "    corpus = []\n",
    "    for doc in tokenized:\n",
    "        tweet = []\n",
    "        tweet.append(tokens['begin'])\n",
    "        for word in doc: \n",
    "            tweet.append(tokens['unknown'] if word not in vocab else word.lower())\n",
    "        tweet.append(tokens['end'])\n",
    "        corpus.append(tweet)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_corpus(vocabSize = -1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, corpus = None):\n",
    "        self.corpus = corpus\n",
    "        self.nGrams = {self.toString(self.gramLen * tokens['unknown']): 0}\n",
    "        self.vocab = {*tokens.values()}\n",
    "        self.nGramsCount = 0\n",
    "        for line in corpus:\n",
    "            self.vocab.update(line)\n",
    "            for gram in self.getNGrams(line):\n",
    "                gram = self.toString(gram)\n",
    "                if not gram in self.nGrams: self.nGrams[gram] = 0\n",
    "                self.nGrams[gram] += 1\n",
    "                self.nGramsCount += 1\n",
    "        self.vocab = list(self.vocab)\n",
    "\n",
    "    def toString(self, gramList):\n",
    "        gram = \"\"\n",
    "        for i in gramList: gram += i\n",
    "        return gram\n",
    "        \n",
    "    def P(self, *words):                                                                # Laplace smoothing\n",
    "        assert len(words) == self.gramLen, \"n-gram doesn't match the expected length\"\n",
    "        gram = self.toString(words)\n",
    "        if not gram in self.nGrams:\n",
    "            self.nGrams[gram] = 0\n",
    "        '''\n",
    "            gram = \"\"\n",
    "            for _ in range(self.gramLen): gram += tokens['unknown']\n",
    "        '''\n",
    "        return (self.nGrams[gram] + 1) / (self.nGramsCount + len(self.nGrams))\n",
    "\n",
    "    def getNGrams(self, line):\n",
    "        return [line[start: start + self.gramLen] for start in range(len(line) - self.gramLen + 1)]\n",
    "\n",
    "    def getProbs(self, sentence):\n",
    "        if isinstance(sentence[0], list):                                               # Naive approach to see if it's a list of lists\n",
    "            sentence = sum(sentence, [])\n",
    "        prob = 0\n",
    "        for gram in self.getNGrams(sentence):\n",
    "            prob += np.log(self.P(*gram))\n",
    "        return np.exp(prob)\n",
    "\n",
    "    def perplexity(self, sentence):                                                     # Include the <s> and </s> tokens, but don't count </s> - (Page 8, Dan Jurafsky on Language Models)\n",
    "        if isinstance(sentence[0], list):                                               # Naive approach to see if it's a list of lists\n",
    "            sentence = sum(sentence, [])\n",
    "        return self.getProbs(sentence) ** (-1 / (len(sentence) - sentence.count(tokens['begin'])) )\n",
    "    \n",
    "    def tweet(self, length = 50):\n",
    "        tweet = [tokens['begin'] for _ in range(self.gramLen - 1)]\n",
    "        for _ in range(length):\n",
    "            ctx = tweet[-self.gramLen + 1:] if self.gramLen > 1 else []\n",
    "            probs = []\n",
    "            for i, w in enumerate(self.vocab):\n",
    "                w = ctx + [w]\n",
    "                p = self.P(*w)\n",
    "                probs.append(p)\n",
    "            print(np.sum(probs))\n",
    "            tweet += [np.random.choice(self.vocab, p = probs / np.sum(probs))]\n",
    "        for t in tweet: print(t + \" \", end = \"\")\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram(LanguageModel):\n",
    "    def __init__(self, corpus = None):\n",
    "        self.gramLen = 1\n",
    "        super().__init__(corpus)\n",
    "\n",
    "class Bigram(LanguageModel):\n",
    "    def __init__(self, corpus = None):\n",
    "        self.gramLen = 2\n",
    "        super().__init__(corpus)      \n",
    "\n",
    "class Trigram(LanguageModel):\n",
    "    def __init__(self, corpus = None):\n",
    "        self.gramLen = 3\n",
    "        super().__init__(corpus)    \n",
    "\n",
    "class N_Gram(LanguageModel):\n",
    "    def __init__(self, gramLen, corpus = None):\n",
    "        self.gramLen = gramLen\n",
    "        super().__init__(corpus)    \n",
    "\n",
    "class Interpolated(LanguageModel):\n",
    "    def __init__(self, corpus = None, models = None, lambdas = None):\n",
    "        #super().__init__(corpus)   \n",
    "        self.lambdas = np.array(lambdas)\n",
    "        self.models = models\n",
    "        assert len(models) == self.lambdas.shape[1], \"The number of models doesn't match the number of lambdas\"\n",
    "\n",
    "    # Currently refactoring to deprecate\n",
    "    def Interpolate(models, set, lambdas):\n",
    "        indProbs = np.zeros((len(models)))\n",
    "        lambdas = np.array(lambdas)\n",
    "        for case in set:\n",
    "            for m, model in enumerate(models):\n",
    "                indProbs[m] += model.getProbs(case)\n",
    "        indProbs /= len(set)\n",
    "        probs = np.dot(indProbs, lambdas.T)\n",
    "        return probs\n",
    "    \n",
    "    def _getProbs(self, sentence):              # Gets the probability of each model\n",
    "        indProbs = np.zeros((len(self.models)))\n",
    "        for m, model in enumerate(self.models):\n",
    "            indProbs[m] += model.getProbs(sentence)\n",
    "        indProbs /= len(set)\n",
    "    \n",
    "    def dev(self, set):\n",
    "        #for case in set:\n",
    "        probs = np.dot(indProbs, self.lambdas.T)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "ya que bien . pa ‚Äú taza pude que si si idem me pendejos la basta \" mas putos hacer yahel me no s√∫per que . ... un sus de al culo <s> se trump verga verte luchona </s> pagar algo curso luchona verga gol ... la mi quise me "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ya',\n",
       " 'que',\n",
       " 'bien',\n",
       " '.',\n",
       " 'pa',\n",
       " '‚Äú',\n",
       " 'taza',\n",
       " 'pude',\n",
       " 'que',\n",
       " 'si',\n",
       " 'si',\n",
       " 'idem',\n",
       " 'me',\n",
       " 'pendejos',\n",
       " 'la',\n",
       " 'basta',\n",
       " '\"',\n",
       " 'mas',\n",
       " 'putos',\n",
       " 'hacer',\n",
       " 'yahel',\n",
       " 'me',\n",
       " 'no',\n",
       " 's√∫per',\n",
       " 'que',\n",
       " '.',\n",
       " '...',\n",
       " 'un',\n",
       " 'sus',\n",
       " 'de',\n",
       " 'al',\n",
       " 'culo',\n",
       " '<s>',\n",
       " 'se',\n",
       " 'trump',\n",
       " 'verga',\n",
       " 'verte',\n",
       " 'luchona',\n",
       " '</s>',\n",
       " 'pagar',\n",
       " 'algo',\n",
       " 'curso',\n",
       " 'luchona',\n",
       " 'verga',\n",
       " 'gol',\n",
       " '...',\n",
       " 'la',\n",
       " 'mi',\n",
       " 'quise',\n",
       " 'me']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = Unigram(corpus)\n",
    "u.tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1072503565899268\n",
      "0.06958087071239473\n",
      "0.06504862720264509\n",
      "0.06112414482405773\n",
      "0.05757618293456146\n",
      "0.054437741283633795\n",
      "0.05161945569604384\n",
      "0.04909328176870287\n",
      "0.046789239309774605\n",
      "0.04469791304501562\n",
      "0.04278540946826084\n",
      "0.04102985987813798\n",
      "0.03941282692827488\n",
      "0.03791855305557881\n",
      "0.03653317100479153\n",
      "0.035349912191173616\n",
      "0.0340503578647198\n",
      "0.03314616236694974\n",
      "0.03188110850702339\n",
      "0.030896151385230133\n",
      "0.02997026797760747\n",
      "0.029098241918378592\n",
      "0.028275501471116064\n",
      "0.027498102668471733\n",
      "0.026762285991805076\n",
      "0.026064788935114037\n",
      "0.025408783289340174\n",
      "0.024773543280568522\n",
      "0.024174713766649057\n",
      "0.02360417261239459\n",
      "0.023069088091679305\n",
      "0.022543938927188506\n",
      "0.022043571674654386\n",
      "0.02157340355701595\n",
      "0.02111298035400583\n",
      "0.020676510931922736\n",
      "0.0202576941253641\n",
      "0.01985549887444158\n",
      "0.019468971545772186\n",
      "0.019097239239588237\n",
      "0.018739415313006928\n",
      "0.01839766594097455\n",
      "0.018064019946182945\n",
      "0.01774219437090176\n",
      "0.01743293259336975\n",
      "0.017134257387066504\n",
      "0.016845676743193712\n",
      "0.016566624109975534\n",
      "0.01629798418822653\n",
      "0.016035422925461847\n",
      "<s> ardidos puntero comer muerta trenes emperra rogelia hacel√≥ contempor√°nea arrebatome s√≠smica denotar cremas vamps a√±o inflado quien astronauta demeritas chismosas pnches transa pesta√±a viejitas layun quiten rubia maletota valgas mam√°s viviendo noooooo flores cojidas intoxicado callo pag√≥ notifique joy preocupate pelea arrepiento hueso ecuador-per√∫ xxx endiablado gob avientan panochas seguirme "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'ardidos',\n",
       " 'puntero',\n",
       " 'comer',\n",
       " 'muerta',\n",
       " 'trenes',\n",
       " 'emperra',\n",
       " 'rogelia',\n",
       " 'hacel√≥',\n",
       " 'contempor√°nea',\n",
       " 'arrebatome',\n",
       " 's√≠smica',\n",
       " 'denotar',\n",
       " 'cremas',\n",
       " 'vamps',\n",
       " 'a√±o',\n",
       " 'inflado',\n",
       " 'quien',\n",
       " 'astronauta',\n",
       " 'demeritas',\n",
       " 'chismosas',\n",
       " 'pnches',\n",
       " 'transa',\n",
       " 'pesta√±a',\n",
       " 'viejitas',\n",
       " 'layun',\n",
       " 'quiten',\n",
       " 'rubia',\n",
       " 'maletota',\n",
       " 'valgas',\n",
       " 'mam√°s',\n",
       " 'viviendo',\n",
       " 'noooooo',\n",
       " 'flores',\n",
       " 'cojidas',\n",
       " 'intoxicado',\n",
       " 'callo',\n",
       " 'pag√≥',\n",
       " 'notifique',\n",
       " 'joy',\n",
       " 'preocupate',\n",
       " 'pelea',\n",
       " 'arrepiento',\n",
       " 'hueso',\n",
       " 'ecuador-per√∫',\n",
       " 'xxx',\n",
       " 'endiablado',\n",
       " 'gob',\n",
       " 'avientan',\n",
       " 'panochas',\n",
       " 'seguirme']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Bigram(corpus)\n",
    "b.tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06467972729209448\n",
      "0.06074919892586585\n",
      "0.057269136021161134\n",
      "0.054166278094493814\n",
      "0.051382437140648676\n",
      "0.048870810289831215\n",
      "0.046593324646440816\n",
      "0.04451869219250624\n",
      "0.04262096263706463\n",
      "0.040878431557241954\n",
      "0.039272806052836756\n",
      "0.03778855972962683\n",
      "0.03641242870999204\n",
      "0.035133013958617426\n",
      "0.03394046464484388\n",
      "0.032826223907232395\n",
      "0.03178282312769476\n",
      "0.03080371424863395\n",
      "0.029883132170456184\n",
      "0.029015981116366357\n",
      "0.028197740231201897\n",
      "0.027424384720107584\n",
      "0.026692319622135134\n",
      "0.025998323918344515\n",
      "0.0253395031405428\n",
      "0.024713249009528954\n",
      "0.02411720491567357\n",
      "0.023549236278411014\n",
      "0.02300740499861839\n",
      "0.022489947359330253\n",
      "0.021995254843695307\n",
      "0.02152185743055359\n",
      "0.021068409002134015\n",
      "0.020633674558723867\n",
      "0.020216518984529076\n",
      "0.019815897149503936\n",
      "0.01943084516539375\n",
      "0.01906047264195608\n",
      "0.018703955812380588\n",
      "0.018360531416171135\n",
      "0.01802949124387391\n",
      "0.01771017726158556\n",
      "0.017401977244602684\n",
      "0.017104320859241864\n",
      "0.0168166761400637\n",
      "0.01653854631671723\n",
      "0.016269466950581145\n",
      "0.016009003346479464\n",
      "0.015756748209127105\n",
      "0.015512319517726948\n",
      "<s> <s> camisa digitalmexp encontramos sacar comparaciones hechos tobillos cantar üé≠ robben ¬∞ jajajjajajaja mono chileno sue√±es levantan villancicos inunde sensual antojas conducta put individuo chivitas mandalay morras terror lana mugroso marcarles espada fracturada disimular ratota casaba motociclista invitas papel√≥n tonto mil vivaldi bunny yeii playsssss protecci√≥n juntaron bromas so√±oliento eres bimbomba "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'camisa',\n",
       " 'digitalmexp',\n",
       " 'encontramos',\n",
       " 'sacar',\n",
       " 'comparaciones',\n",
       " 'hechos',\n",
       " 'tobillos',\n",
       " 'cantar',\n",
       " 'üé≠',\n",
       " 'robben',\n",
       " '¬∞',\n",
       " 'jajajjajajaja',\n",
       " 'mono',\n",
       " 'chileno',\n",
       " 'sue√±es',\n",
       " 'levantan',\n",
       " 'villancicos',\n",
       " 'inunde',\n",
       " 'sensual',\n",
       " 'antojas',\n",
       " 'conducta',\n",
       " 'put',\n",
       " 'individuo',\n",
       " 'chivitas',\n",
       " 'mandalay',\n",
       " 'morras',\n",
       " 'terror',\n",
       " 'lana',\n",
       " 'mugroso',\n",
       " 'marcarles',\n",
       " 'espada',\n",
       " 'fracturada',\n",
       " 'disimular',\n",
       " 'ratota',\n",
       " 'casaba',\n",
       " 'motociclista',\n",
       " 'invitas',\n",
       " 'papel√≥n',\n",
       " 'tonto',\n",
       " 'mil',\n",
       " 'vivaldi',\n",
       " 'bunny',\n",
       " 'yeii',\n",
       " 'playsssss',\n",
       " 'protecci√≥n',\n",
       " 'juntaron',\n",
       " 'bromas',\n",
       " 'so√±oliento',\n",
       " 'eres',\n",
       " 'bimbomba']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Trigram(corpus)\n",
    "t.tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027060526336833184\n",
      "0.04434119933148345\n",
      "7.996545492347306e-06\n"
     ]
    }
   ],
   "source": [
    "uni = Unigram(corpus)\n",
    "\n",
    "# Very frequent\n",
    "print(uni.P(\"que\"))\n",
    "print(uni.P(tokens['begin']))\n",
    "\n",
    "# Doesn't exist\n",
    "print(uni.P(\"otorrinolaringologo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008420459141775038\n",
      "0.0004964026131614105\n",
      "6.128389765589092e-06\n"
     ]
    }
   ],
   "source": [
    "bi = Bigram(corpus)\n",
    "\n",
    "# Very frequent \n",
    "print(bi.P('.', tokens['end']))\n",
    "print(bi.P(\"es\", \"que\"))\n",
    "\n",
    "# Doesn't exist\n",
    "print(bi.P(tokens['begin'], tokens['end']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011204392546689393\n",
      "4.7791247829480825e-05\n",
      "5.310110450297366e-06\n"
     ]
    }
   ],
   "source": [
    "tri = Trigram(corpus)\n",
    "\n",
    "# Very frequent\n",
    "print(tri.P('!', '!', '!'))\n",
    "print(tri.P('es', 'que', 'no'))\n",
    "\n",
    "# Doesn't exist\n",
    "print(tri.P('Luis', 'Eduardo', 'Robles'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Interpolated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of stratified sets:\n",
      "\tTrain: 4435\n",
      "\tTest: 554\n",
      "\tValidation: 555\n"
     ]
    }
   ],
   "source": [
    "c_train, c_test = train_test_split(corpus, test_size = 0.2, train_size = 0.8)\n",
    "c_test, c_val = train_test_split(c_test, test_size = 0.5, train_size = 0.5)\n",
    "print(f'Lengths of stratified sets:\\n\\tTrain: {len(c_train)}\\n\\tTest: {len(c_test)}\\n\\tValidation: {len(c_val)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO - Not needed but strange behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf inf inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalor\\AppData\\Local\\Temp\\ipykernel_19920\\3035203680.py:46: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return self.getProbs(sentence) ** (-1 / (len(sentence) - sentence.count(tokens['begin'])) )\n"
     ]
    }
   ],
   "source": [
    "uni, bi, tri = Unigram(c_train), Bigram(c_train), Trigram(c_train)\n",
    "pU, pB, pT = uni.perplexity(c_val), bi.perplexity(c_val), tri.perplexity(c_val)\n",
    "print(pU, pB, pT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [(1/3, 1/3, 1/3), (0.4, 0.4, 0.2), (0.2, 0.4, 0.4), (0.5, 0.4, 0.1), (0.1, 0.4, 0.5), (0.9, 0.05, 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npps = Interpolated.Interpolate([uni, bi, tri], c_test, params) ** (-1 / len(c_test))\\nordered = np.argsort(pps)\\nprint(\"Params ordered by perplexity\")\\nfor p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is wrong\n",
    "'''\n",
    "pps = Interpolated.Interpolate([uni, bi, tri], c_test, params) ** (-1 / len(c_test))\n",
    "ordered = np.argsort(pps)\n",
    "print(\"Params ordered by perplexity\")\n",
    "for p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npps = Interpolated(models = [uni, bi, tri], lambdas = params).dev(c_test) ** (-1 / len(c_test))\\nordered = np.argsort(pps)\\nprint(\"Params ordered by perplexity\")\\nfor p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pps = Interpolated(models = [uni, bi, tri], lambdas = params).dev(c_test) ** (-1 / len(c_test))\n",
    "ordered = np.argsort(pps)\n",
    "print(\"Params ordered by perplexity\")\n",
    "for p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tweet Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "qu√© que a caga üò° las la quisieras carpintero himno proteja hacer <s> con pinche los putos </s> concurso trabajo entro <s> a . . toda sean pq ? doy </s> ? ecuador como @usuario con hueva modem preferido maricon largo loca </s> el @usuario les cuando . pinche las "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['qu√©',\n",
       " 'que',\n",
       " 'a',\n",
       " 'caga',\n",
       " 'üò°',\n",
       " 'las',\n",
       " 'la',\n",
       " 'quisieras',\n",
       " 'carpintero',\n",
       " 'himno',\n",
       " 'proteja',\n",
       " 'hacer',\n",
       " '<s>',\n",
       " 'con',\n",
       " 'pinche',\n",
       " 'los',\n",
       " 'putos',\n",
       " '</s>',\n",
       " 'concurso',\n",
       " 'trabajo',\n",
       " 'entro',\n",
       " '<s>',\n",
       " 'a',\n",
       " '.',\n",
       " '.',\n",
       " 'toda',\n",
       " 'sean',\n",
       " 'pq',\n",
       " '?',\n",
       " 'doy',\n",
       " '</s>',\n",
       " '?',\n",
       " 'ecuador',\n",
       " 'como',\n",
       " '@usuario',\n",
       " 'con',\n",
       " 'hueva',\n",
       " 'modem',\n",
       " 'preferido',\n",
       " 'maricon',\n",
       " 'largo',\n",
       " 'loca',\n",
       " '</s>',\n",
       " 'el',\n",
       " '@usuario',\n",
       " 'les',\n",
       " 'cuando',\n",
       " '.',\n",
       " 'pinche',\n",
       " 'las']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni = Unigram(c_train)\n",
    "uni.tweet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AMLO model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation with custom phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. More evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El ahorcado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Norvig's Hangman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Follow-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
