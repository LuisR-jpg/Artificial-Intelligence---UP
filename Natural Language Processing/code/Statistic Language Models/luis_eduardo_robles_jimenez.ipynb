{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Model Languages\n",
    "\n",
    "Tarea 3 - Luis Eduardo Robles Jimenez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = dict()\n",
    "tokens['begin'], tokens['end'], tokens['unknown'] = '<s>', '</s>', '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_vocabulary(corpus, size):                           # Returns words sorted by frequency\n",
    "    words, tokenizer, corpusByWords = [], TweetTokenizer(), []\n",
    "    for doc in corpus:\n",
    "        tokens = tokenizer.tokenize(doc)\n",
    "        words += tokens\n",
    "        corpusByWords += [tokens]\n",
    "    count = nltk.FreqDist(words)\n",
    "    count = sorted([(count[key], key) for key in count])[::-1]\n",
    "    if size != -1: count = count[:size]\n",
    "    return [word for _, word in count], corpusByWords\n",
    "\n",
    "def load_corpus(corpus_select = \"tweets\", vocabSize = 100):\n",
    "    corpus = []\n",
    "    path_corpus = \"../../data/agresividad/mex_train.txt\"\n",
    "\n",
    "    with open(path_corpus, \"r\") as f_corpus:\n",
    "        for tuit in f_corpus:\n",
    "            corpus += [tuit[:-1]]\n",
    "    \n",
    "    vocab, tokenized = _create_vocabulary(corpus, vocabSize)\n",
    "    corpus = []\n",
    "    for doc in tokenized:\n",
    "        tweet = []\n",
    "        tweet.append(tokens['begin'])\n",
    "        for word in doc: \n",
    "            tweet.append(tokens['unknown'] if word not in vocab else word.lower())\n",
    "        tweet.append(tokens['end'])\n",
    "        corpus.append(tweet)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_corpus(vocabSize = -1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel:\n",
    "    def __init__(self, corpus = None):\n",
    "        self.corpus = corpus\n",
    "        self.nGrams = {self.toString(self.gramLen * tokens['unknown']): 0}\n",
    "        self.vocab = {*tokens.values()}\n",
    "        self.nGramsCount = 0\n",
    "        for line in corpus:\n",
    "            self.vocab.update(line)\n",
    "            for gram in self.getNGrams(line):\n",
    "                gram = self.toString(gram)\n",
    "                if not gram in self.nGrams: self.nGrams[gram] = 0\n",
    "                self.nGrams[gram] += 1\n",
    "                self.nGramsCount += 1\n",
    "        self.vocab = list(self.vocab)\n",
    "\n",
    "    def toString(self, gramList):\n",
    "        gram = \"\"\n",
    "        for i in gramList: gram += i\n",
    "        return gram\n",
    "        \n",
    "    def P(self, *words):                                                                # Laplace smoothing\n",
    "        assert len(words) == self.gramLen, \"n-gram doesn't match the expected length\"\n",
    "        gram = self.toString(words)\n",
    "        if not gram in self.nGrams:\n",
    "            self.nGrams[gram] = 0\n",
    "        '''\n",
    "            gram = \"\"\n",
    "            for _ in range(self.gramLen): gram += tokens['unknown']\n",
    "        '''\n",
    "        return (self.nGrams[gram] + 1) / (self.nGramsCount + len(self.nGrams))\n",
    "\n",
    "    def getNGrams(self, line):\n",
    "        return [line[start: start + self.gramLen] for start in range(len(line) - self.gramLen + 1)]\n",
    "\n",
    "    def getProbs(self, sentence):\n",
    "        if isinstance(sentence[0], list):                                               # Naive approach to see if it's a list of lists\n",
    "            sentence = sum(sentence, [])\n",
    "        prob = 0\n",
    "        for gram in self.getNGrams(sentence):\n",
    "            prob += np.log(self.P(*gram))\n",
    "        return np.exp(prob)\n",
    "\n",
    "    def perplexity(self, sentence):                                                     # Include the <s> and </s> tokens, but don't count </s> - (Page 8, Dan Jurafsky on Language Models)\n",
    "        if isinstance(sentence[0], list):                                               # Naive approach to see if it's a list of lists\n",
    "            sentence = sum(sentence, [])\n",
    "        return self.getProbs(sentence) ** (-1 / (len(sentence) - sentence.count(tokens['begin'])) )\n",
    "    \n",
    "    def tweet(self, length = 50):\n",
    "        tweet = [tokens['begin'] for _ in range(self.gramLen - 1)]\n",
    "        for _ in range(length):\n",
    "            ctx = tweet[-self.gramLen + 1:] if self.gramLen > 1 else []\n",
    "            probs = []\n",
    "            for i, w in enumerate(self.vocab):\n",
    "                w = ctx + [w]\n",
    "                p = self.P(*w)\n",
    "                probs.append(p)\n",
    "            print(np.sum(probs))\n",
    "            tweet += [np.random.choice(self.vocab, p = probs / np.sum(probs))]\n",
    "        for t in tweet: print(t + \" \", end = \"\")\n",
    "        return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unigram(LanguageModel):\n",
    "    def __init__(self, corpus = None):\n",
    "        self.gramLen = 1\n",
    "        super().__init__(corpus)\n",
    "\n",
    "class Bigram(LanguageModel):\n",
    "    def __init__(self, corpus = None):\n",
    "        self.gramLen = 2\n",
    "        super().__init__(corpus)      \n",
    "\n",
    "class Trigram(LanguageModel):\n",
    "    def __init__(self, corpus = None):\n",
    "        self.gramLen = 3\n",
    "        super().__init__(corpus)    \n",
    "\n",
    "class N_Gram(LanguageModel):\n",
    "    def __init__(self, gramLen, corpus = None):\n",
    "        self.gramLen = gramLen\n",
    "        super().__init__(corpus)    \n",
    "\n",
    "class Interpolated(LanguageModel):\n",
    "    def __init__(self, corpus = None, models = None, lambdas = None):\n",
    "        #super().__init__(corpus)   \n",
    "        self.lambdas = np.array(lambdas)\n",
    "        self.models = models\n",
    "        assert len(models) == self.lambdas.shape[1], \"The number of models doesn't match the number of lambdas\"\n",
    "\n",
    "    # Currently refactoring to deprecate\n",
    "    def Interpolate(models, set, lambdas):\n",
    "        indProbs = np.zeros((len(models)))\n",
    "        lambdas = np.array(lambdas)\n",
    "        for case in set:\n",
    "            for m, model in enumerate(models):\n",
    "                indProbs[m] += model.getProbs(case)\n",
    "        indProbs /= len(set)\n",
    "        probs = np.dot(indProbs, lambdas.T)\n",
    "        return probs\n",
    "    \n",
    "    def _getProbs(self, sentence):              # Gets the probability of each model\n",
    "        indProbs = np.zeros((len(self.models)))\n",
    "        for m, model in enumerate(self.models):\n",
    "            indProbs[m] += model.getProbs(sentence)\n",
    "        indProbs /= len(set)\n",
    "    \n",
    "    def dev(self, set):\n",
    "        #for case in set:\n",
    "        probs = np.dot(indProbs, self.lambdas.T)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "ya que bien . pa “ taza pude que si si idem me pendejos la basta \" mas putos hacer yahel me no súper que . ... un sus de al culo <s> se trump verga verte luchona </s> pagar algo curso luchona verga gol ... la mi quise me "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ya',\n",
       " 'que',\n",
       " 'bien',\n",
       " '.',\n",
       " 'pa',\n",
       " '“',\n",
       " 'taza',\n",
       " 'pude',\n",
       " 'que',\n",
       " 'si',\n",
       " 'si',\n",
       " 'idem',\n",
       " 'me',\n",
       " 'pendejos',\n",
       " 'la',\n",
       " 'basta',\n",
       " '\"',\n",
       " 'mas',\n",
       " 'putos',\n",
       " 'hacer',\n",
       " 'yahel',\n",
       " 'me',\n",
       " 'no',\n",
       " 'súper',\n",
       " 'que',\n",
       " '.',\n",
       " '...',\n",
       " 'un',\n",
       " 'sus',\n",
       " 'de',\n",
       " 'al',\n",
       " 'culo',\n",
       " '<s>',\n",
       " 'se',\n",
       " 'trump',\n",
       " 'verga',\n",
       " 'verte',\n",
       " 'luchona',\n",
       " '</s>',\n",
       " 'pagar',\n",
       " 'algo',\n",
       " 'curso',\n",
       " 'luchona',\n",
       " 'verga',\n",
       " 'gol',\n",
       " '...',\n",
       " 'la',\n",
       " 'mi',\n",
       " 'quise',\n",
       " 'me']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = Unigram(corpus)\n",
    "u.tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1072503565899268\n",
      "0.06958087071239473\n",
      "0.06504862720264509\n",
      "0.06112414482405773\n",
      "0.05757618293456146\n",
      "0.054437741283633795\n",
      "0.05161945569604384\n",
      "0.04909328176870287\n",
      "0.046789239309774605\n",
      "0.04469791304501562\n",
      "0.04278540946826084\n",
      "0.04102985987813798\n",
      "0.03941282692827488\n",
      "0.03791855305557881\n",
      "0.03653317100479153\n",
      "0.035349912191173616\n",
      "0.0340503578647198\n",
      "0.03314616236694974\n",
      "0.03188110850702339\n",
      "0.030896151385230133\n",
      "0.02997026797760747\n",
      "0.029098241918378592\n",
      "0.028275501471116064\n",
      "0.027498102668471733\n",
      "0.026762285991805076\n",
      "0.026064788935114037\n",
      "0.025408783289340174\n",
      "0.024773543280568522\n",
      "0.024174713766649057\n",
      "0.02360417261239459\n",
      "0.023069088091679305\n",
      "0.022543938927188506\n",
      "0.022043571674654386\n",
      "0.02157340355701595\n",
      "0.02111298035400583\n",
      "0.020676510931922736\n",
      "0.0202576941253641\n",
      "0.01985549887444158\n",
      "0.019468971545772186\n",
      "0.019097239239588237\n",
      "0.018739415313006928\n",
      "0.01839766594097455\n",
      "0.018064019946182945\n",
      "0.01774219437090176\n",
      "0.01743293259336975\n",
      "0.017134257387066504\n",
      "0.016845676743193712\n",
      "0.016566624109975534\n",
      "0.01629798418822653\n",
      "0.016035422925461847\n",
      "<s> ardidos puntero comer muerta trenes emperra rogelia haceló contemporánea arrebatome sísmica denotar cremas vamps año inflado quien astronauta demeritas chismosas pnches transa pestaña viejitas layun quiten rubia maletota valgas mamás viviendo noooooo flores cojidas intoxicado callo pagó notifique joy preocupate pelea arrepiento hueso ecuador-perú xxx endiablado gob avientan panochas seguirme "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'ardidos',\n",
       " 'puntero',\n",
       " 'comer',\n",
       " 'muerta',\n",
       " 'trenes',\n",
       " 'emperra',\n",
       " 'rogelia',\n",
       " 'haceló',\n",
       " 'contemporánea',\n",
       " 'arrebatome',\n",
       " 'sísmica',\n",
       " 'denotar',\n",
       " 'cremas',\n",
       " 'vamps',\n",
       " 'año',\n",
       " 'inflado',\n",
       " 'quien',\n",
       " 'astronauta',\n",
       " 'demeritas',\n",
       " 'chismosas',\n",
       " 'pnches',\n",
       " 'transa',\n",
       " 'pestaña',\n",
       " 'viejitas',\n",
       " 'layun',\n",
       " 'quiten',\n",
       " 'rubia',\n",
       " 'maletota',\n",
       " 'valgas',\n",
       " 'mamás',\n",
       " 'viviendo',\n",
       " 'noooooo',\n",
       " 'flores',\n",
       " 'cojidas',\n",
       " 'intoxicado',\n",
       " 'callo',\n",
       " 'pagó',\n",
       " 'notifique',\n",
       " 'joy',\n",
       " 'preocupate',\n",
       " 'pelea',\n",
       " 'arrepiento',\n",
       " 'hueso',\n",
       " 'ecuador-perú',\n",
       " 'xxx',\n",
       " 'endiablado',\n",
       " 'gob',\n",
       " 'avientan',\n",
       " 'panochas',\n",
       " 'seguirme']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Bigram(corpus)\n",
    "b.tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06467972729209448\n",
      "0.06074919892586585\n",
      "0.057269136021161134\n",
      "0.054166278094493814\n",
      "0.051382437140648676\n",
      "0.048870810289831215\n",
      "0.046593324646440816\n",
      "0.04451869219250624\n",
      "0.04262096263706463\n",
      "0.040878431557241954\n",
      "0.039272806052836756\n",
      "0.03778855972962683\n",
      "0.03641242870999204\n",
      "0.035133013958617426\n",
      "0.03394046464484388\n",
      "0.032826223907232395\n",
      "0.03178282312769476\n",
      "0.03080371424863395\n",
      "0.029883132170456184\n",
      "0.029015981116366357\n",
      "0.028197740231201897\n",
      "0.027424384720107584\n",
      "0.026692319622135134\n",
      "0.025998323918344515\n",
      "0.0253395031405428\n",
      "0.024713249009528954\n",
      "0.02411720491567357\n",
      "0.023549236278411014\n",
      "0.02300740499861839\n",
      "0.022489947359330253\n",
      "0.021995254843695307\n",
      "0.02152185743055359\n",
      "0.021068409002134015\n",
      "0.020633674558723867\n",
      "0.020216518984529076\n",
      "0.019815897149503936\n",
      "0.01943084516539375\n",
      "0.01906047264195608\n",
      "0.018703955812380588\n",
      "0.018360531416171135\n",
      "0.01802949124387391\n",
      "0.01771017726158556\n",
      "0.017401977244602684\n",
      "0.017104320859241864\n",
      "0.0168166761400637\n",
      "0.01653854631671723\n",
      "0.016269466950581145\n",
      "0.016009003346479464\n",
      "0.015756748209127105\n",
      "0.015512319517726948\n",
      "<s> <s> camisa digitalmexp encontramos sacar comparaciones hechos tobillos cantar 🎭 robben ° jajajjajajaja mono chileno sueñes levantan villancicos inunde sensual antojas conducta put individuo chivitas mandalay morras terror lana mugroso marcarles espada fracturada disimular ratota casaba motociclista invitas papelón tonto mil vivaldi bunny yeii playsssss protección juntaron bromas soñoliento eres bimbomba "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'camisa',\n",
       " 'digitalmexp',\n",
       " 'encontramos',\n",
       " 'sacar',\n",
       " 'comparaciones',\n",
       " 'hechos',\n",
       " 'tobillos',\n",
       " 'cantar',\n",
       " '🎭',\n",
       " 'robben',\n",
       " '°',\n",
       " 'jajajjajajaja',\n",
       " 'mono',\n",
       " 'chileno',\n",
       " 'sueñes',\n",
       " 'levantan',\n",
       " 'villancicos',\n",
       " 'inunde',\n",
       " 'sensual',\n",
       " 'antojas',\n",
       " 'conducta',\n",
       " 'put',\n",
       " 'individuo',\n",
       " 'chivitas',\n",
       " 'mandalay',\n",
       " 'morras',\n",
       " 'terror',\n",
       " 'lana',\n",
       " 'mugroso',\n",
       " 'marcarles',\n",
       " 'espada',\n",
       " 'fracturada',\n",
       " 'disimular',\n",
       " 'ratota',\n",
       " 'casaba',\n",
       " 'motociclista',\n",
       " 'invitas',\n",
       " 'papelón',\n",
       " 'tonto',\n",
       " 'mil',\n",
       " 'vivaldi',\n",
       " 'bunny',\n",
       " 'yeii',\n",
       " 'playsssss',\n",
       " 'protección',\n",
       " 'juntaron',\n",
       " 'bromas',\n",
       " 'soñoliento',\n",
       " 'eres',\n",
       " 'bimbomba']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Trigram(corpus)\n",
    "t.tweet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027060526336833184\n",
      "0.04434119933148345\n",
      "7.996545492347306e-06\n"
     ]
    }
   ],
   "source": [
    "uni = Unigram(corpus)\n",
    "\n",
    "# Very frequent\n",
    "print(uni.P(\"que\"))\n",
    "print(uni.P(tokens['begin']))\n",
    "\n",
    "# Doesn't exist\n",
    "print(uni.P(\"otorrinolaringologo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008420459141775038\n",
      "0.0004964026131614105\n",
      "6.128389765589092e-06\n"
     ]
    }
   ],
   "source": [
    "bi = Bigram(corpus)\n",
    "\n",
    "# Very frequent \n",
    "print(bi.P('.', tokens['end']))\n",
    "print(bi.P(\"es\", \"que\"))\n",
    "\n",
    "# Doesn't exist\n",
    "print(bi.P(tokens['begin'], tokens['end']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011204392546689393\n",
      "4.7791247829480825e-05\n",
      "5.310110450297366e-06\n"
     ]
    }
   ],
   "source": [
    "tri = Trigram(corpus)\n",
    "\n",
    "# Very frequent\n",
    "print(tri.P('!', '!', '!'))\n",
    "print(tri.P('es', 'que', 'no'))\n",
    "\n",
    "# Doesn't exist\n",
    "print(tri.P('Luis', 'Eduardo', 'Robles'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Interpolated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of stratified sets:\n",
      "\tTrain: 4435\n",
      "\tTest: 554\n",
      "\tValidation: 555\n"
     ]
    }
   ],
   "source": [
    "c_train, c_test = train_test_split(corpus, test_size = 0.2, train_size = 0.8)\n",
    "c_test, c_val = train_test_split(c_test, test_size = 0.5, train_size = 0.5)\n",
    "print(f'Lengths of stratified sets:\\n\\tTrain: {len(c_train)}\\n\\tTest: {len(c_test)}\\n\\tValidation: {len(c_val)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO - Not needed but strange behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf inf inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lalor\\AppData\\Local\\Temp\\ipykernel_19920\\3035203680.py:46: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return self.getProbs(sentence) ** (-1 / (len(sentence) - sentence.count(tokens['begin'])) )\n"
     ]
    }
   ],
   "source": [
    "uni, bi, tri = Unigram(c_train), Bigram(c_train), Trigram(c_train)\n",
    "pU, pB, pT = uni.perplexity(c_val), bi.perplexity(c_val), tri.perplexity(c_val)\n",
    "print(pU, pB, pT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [(1/3, 1/3, 1/3), (0.4, 0.4, 0.2), (0.2, 0.4, 0.4), (0.5, 0.4, 0.1), (0.1, 0.4, 0.5), (0.9, 0.05, 0.05)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npps = Interpolated.Interpolate([uni, bi, tri], c_test, params) ** (-1 / len(c_test))\\nordered = np.argsort(pps)\\nprint(\"Params ordered by perplexity\")\\nfor p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is wrong\n",
    "'''\n",
    "pps = Interpolated.Interpolate([uni, bi, tri], c_test, params) ** (-1 / len(c_test))\n",
    "ordered = np.argsort(pps)\n",
    "print(\"Params ordered by perplexity\")\n",
    "for p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npps = Interpolated(models = [uni, bi, tri], lambdas = params).dev(c_test) ** (-1 / len(c_test))\\nordered = np.argsort(pps)\\nprint(\"Params ordered by perplexity\")\\nfor p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pps = Interpolated(models = [uni, bi, tri], lambdas = params).dev(c_test) ** (-1 / len(c_test))\n",
    "ordered = np.argsort(pps)\n",
    "print(\"Params ordered by perplexity\")\n",
    "for p in ordered: print(f\"\\t{np.round(params[p], decimals = 1)} with a value of {pps[p]}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tweet Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "qué que a caga 😡 las la quisieras carpintero himno proteja hacer <s> con pinche los putos </s> concurso trabajo entro <s> a . . toda sean pq ? doy </s> ? ecuador como @usuario con hueva modem preferido maricon largo loca </s> el @usuario les cuando . pinche las "
     ]
    },
    {
     "data": {
      "text/plain": [
       "['qué',\n",
       " 'que',\n",
       " 'a',\n",
       " 'caga',\n",
       " '😡',\n",
       " 'las',\n",
       " 'la',\n",
       " 'quisieras',\n",
       " 'carpintero',\n",
       " 'himno',\n",
       " 'proteja',\n",
       " 'hacer',\n",
       " '<s>',\n",
       " 'con',\n",
       " 'pinche',\n",
       " 'los',\n",
       " 'putos',\n",
       " '</s>',\n",
       " 'concurso',\n",
       " 'trabajo',\n",
       " 'entro',\n",
       " '<s>',\n",
       " 'a',\n",
       " '.',\n",
       " '.',\n",
       " 'toda',\n",
       " 'sean',\n",
       " 'pq',\n",
       " '?',\n",
       " 'doy',\n",
       " '</s>',\n",
       " '?',\n",
       " 'ecuador',\n",
       " 'como',\n",
       " '@usuario',\n",
       " 'con',\n",
       " 'hueva',\n",
       " 'modem',\n",
       " 'preferido',\n",
       " 'maricon',\n",
       " 'largo',\n",
       " 'loca',\n",
       " '</s>',\n",
       " 'el',\n",
       " '@usuario',\n",
       " 'les',\n",
       " 'cuando',\n",
       " '.',\n",
       " 'pinche',\n",
       " 'las']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni = Unigram(c_train)\n",
    "uni.tweet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. AMLO model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation with custom phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. More evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El ahorcado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Norvig's Hangman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Follow-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
