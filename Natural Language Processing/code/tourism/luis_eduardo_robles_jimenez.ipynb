{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas\n",
    "\n",
    "- Cual es el numero de tarea? The doc says proyecto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntext = \"Hola como estas, jajajaja, que haces?\"\\ntext = \"The quick brown fox jumps over the lazy dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog \"\\n\\nwordcloud = WordCloud(width=800, height=800, background_color=\\'white\\', min_font_size=3).generate(text)\\n\\nplt.figure(figsize=(8,8))\\nplt.imshow(wordcloud)\\nplt.axis(\"off\")\\nplt.tight_layout(pad=0)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "text = \"Hola como estas, jajajaja, que haces?\"\n",
    "text = \"The quick brown fox jumps over the lazy dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog \"\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=3).generate(text)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto 1 - Luis Eduardo Robles Jimenez\n",
    "\n",
    "# Minería de Texto para Turismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TouristSpot:\n",
    "    def __init__(self, path):\n",
    "        self.reviews = pd.read_csv(path)\n",
    "        self.spotName = path.split('/')[-1][: -4]\n",
    "        self._cleanUp()\n",
    "        self.nDashes = 30\n",
    "\n",
    "    def _cleanUp(self):\n",
    "        #self.reviews.columns = [c.strip() for c in self.reviews.columns]\n",
    "\n",
    "        #if self.reviews.loc[:, 'Edad'].dtypes == object: self.reviews.loc[:, 'Edad'] = [n.strip() for n in self.reviews.loc[:, 'Edad']]\n",
    "        #self.reviews.loc[:, 'Edad'] = self.reviews.loc[:, 'Edad'].replace([np.nan, ''], -1)\n",
    "        #self.reviews.loc[:, 'Edad'] = self.reviews.loc[:, 'Edad'].astype('int32')\n",
    "\n",
    "        columns = [\"Título de la opinión\", \"Opinión\"]\n",
    "        for col in columns:\n",
    "            desc = []\n",
    "            for o in self.reviews.loc[:, col]:\n",
    "                if o[0] == '\"': o = o[1:]\n",
    "                if o[-1] == '\"': o = o[:-1]\n",
    "                desc.append(o)\n",
    "            self.reviews.loc[:, col] = desc\n",
    "\n",
    "    def wordCloud(self):\n",
    "        #pip install wordcloud\n",
    "        pass\n",
    "\n",
    "    def LSA(self):\n",
    "        subgroups = []\n",
    "        subgroups.append(self.reviews.loc[self.reviews.loc[:, 'Género'] == 'Masculino'])\n",
    "        subgroups.append(self.reviews.loc[self.reviews.loc[:, 'Género'] == 'Femenino'])\n",
    "        subgroups.append(self.reviews.loc[self.reviews.loc[:, 'Nacional ó Internacional'] == 'Nacional'])\n",
    "        subgroups.append(self.reviews.loc[self.reviews.loc[:, 'Nacional ó Internacional'] == 'Internacional'])\n",
    "        subgroups.append(np.logical_and(self.reviews.loc[:, 'Edad'] < 10, self.reviews.loc[:, 'Edad'] < 30))\n",
    "        subgroups.append(np.logical_and(self.reviews.loc[:, 'Edad'] < 60, self.reviews.loc[:, 'Edad'] < 100))\n",
    "\n",
    "        for s in subgroups:\n",
    "            vectorizer = TfidfVectorizer(min_df = 1)\n",
    "            bow = vectorizer.fit_transform(s)\n",
    "            terms = vectorizer.get_feature_names()\n",
    "            \n",
    "            bow = preprocessing.normalize(bow, norm = 'l2')\n",
    "            svd = TruncatedSVD(n_components = 3)\n",
    "            lsa = svd.fit_transform(bow)\n",
    "\n",
    "            for i, comp in enumerate(lsa.components_):\n",
    "                print(f\"Componente {i}:\")\n",
    "                terms_comp = zip(terms, comp)\n",
    "                sorted_terms = sorted(terms_comp, key=lambda x:x[1], reverse=True)[:10]\n",
    "                for t in sorted_terms:\n",
    "                    print(t[0], end=',')\n",
    "                print('\\n')\n",
    "\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def temporalAnalysis(self):\n",
    "\n",
    "        self.reviews['newDate'] = ['/'.join(date.split('/')[1:]) for date in self.reviews.loc[:, 'Fecha']]\n",
    "\n",
    "        dates = []\n",
    "        bad, neutral, good, total = [], [], [], []\n",
    "        for groupName, reviewsGroup in self.reviews.groupby('newDate'):\n",
    "            dates.append(groupName)\n",
    "            bad.append(np.sum(reviewsGroup.loc[:, 'Escala'] < 3))\n",
    "            neutral.append(np.sum(reviewsGroup.loc[:, 'Escala'] == 3))\n",
    "            good.append(np.sum(reviewsGroup.loc[:, 'Escala'] > 3))\n",
    "\n",
    "        grades = np.array(bad) + np.array(neutral) + np.array(good)\n",
    "        bad =       np.array(bad)       / grades * 100\n",
    "        neutral =   np.array(neutral)   / grades * 100\n",
    "        good =      np.array(good)      / grades * 100\n",
    "\n",
    "        argsort = np.argsort([datetime.strptime(date, '%m/%y' if len(date) == 5 else '%m/%Y') for date in dates])[::-1]\n",
    "        dates =     np.array([dates[i] for i in argsort])\n",
    "        bad =       np.array([bad[i] for i in argsort])\n",
    "        neutral =   np.array([neutral[i] for i in argsort])\n",
    "        good =      np.array([good[i] for i in argsort])\n",
    "\n",
    "\n",
    "        _, stackedChart = plt.subplots(figsize = (15, 15))\n",
    "        stackedChart.barh(dates, good, label='Good reviews', color = '#00ff00')\n",
    "        stackedChart.barh(dates, neutral, left = good, label='Neutral reviews', color = '#ffff00')\n",
    "        stackedChart.barh(dates, bad, left = good + neutral, label='Bad reviews', color = '#ff0000')\n",
    "        stackedChart.legend()\n",
    "        stackedChart.set_title(f'Reviews of {self.spotName} by month')\n",
    "        plt.show()\n",
    "\n",
    "    def describe(self):\n",
    "        nRows, nCols = 2, 1\n",
    "        fig = plt.figure(figsize = (15, 10))\n",
    "        fig.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "        print(self.nDashes * '-', self.spotName, self.nDashes * '-')\n",
    "\n",
    "        grades = fig.add_subplot(321)\n",
    "        avg = np.round(np.average(self.reviews.loc[:, 'Escala']), decimals = 2)\n",
    "        sd = np.round(np.std(self.reviews.loc[:, 'Escala']), decimals = 2)\n",
    "        grades.hist(self.reviews.loc[:, 'Escala'])\n",
    "        grades.set_title(f\"Grades (1 worst; 5 best); Average = {avg}; SD = {sd}\")\n",
    "\n",
    "        length = fig.add_subplot(322)\n",
    "        lenOpinions = [len(TweetTokenizer().tokenize(o)) for o in self.reviews.loc[:, 'Opinión']]\n",
    "        avg = np.round(np.average(lenOpinions), decimals = 2)\n",
    "        sd = np.round(np.std(lenOpinions), decimals = 2)\n",
    "        length.hist(lenOpinions)\n",
    "        length.set_title(f\"Length of opinions (words); Average = {avg}; SD = {sd}\")\n",
    "\n",
    "        ages = fig.add_subplot(323)\n",
    "        ages.hist(self.reviews.loc[:, 'Edad'], bins = 10)\n",
    "        ages.set_title(f'Ages distribution')\n",
    "\n",
    "        visitors = fig.add_subplot(324)\n",
    "        visitors.hist(self.reviews.loc[:, 'Nacional ó Internacional'])\n",
    "        visitors.set_title('Local or foreigner')\n",
    "\n",
    "        monthNames = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        popularity = fig.add_subplot(325)\n",
    "        months = [int(d.split('/')[1]) for d in self.reviews.loc[:, 'Fecha']]\n",
    "        m, c = np.unique(months, return_counts = True)\n",
    "        popularity.bar(m, c)\n",
    "        popularity.set_title('Popularity by month')\n",
    "        popularity.set_xticks(np.arange(1, len(m) + 1), labels = monthNames)\n",
    "\n",
    "        languages = fig.add_subplot(326)\n",
    "        m, c = np.unique(self.reviews.loc[:, 'Idioma'], return_counts = True)\n",
    "        languages.barh(m, c)\n",
    "        languages.set_title('Language')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividades\n",
    "\n",
    "### 1. Preprocesamiento y stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/guanajuato/\"\n",
    "spots = [TouristSpot(os.path.join(path, d)) for d in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.describe()\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.temporalAnalysis()\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TfidfVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[212], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m spot \u001b[39min\u001b[39;00m spots: \n\u001b[1;32m----> 2\u001b[0m     spot\u001b[39m.\u001b[39;49mLSA()\n\u001b[0;32m      3\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[208], line 40\u001b[0m, in \u001b[0;36mTouristSpot.LSA\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m vectorizer \u001b[39m=\u001b[39m TfidfVectorizer(min_df \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     39\u001b[0m bow \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mfit_transform(s)\n\u001b[1;32m---> 40\u001b[0m terms \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mget_feature_names()\n\u001b[0;32m     42\u001b[0m bow \u001b[39m=\u001b[39m preprocessing\u001b[39m.\u001b[39mnormalize(bow, norm \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m svd \u001b[39m=\u001b[39m TruncatedSVD(n_components \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TfidfVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "for spot in spots: \n",
    "    spot.LSA()\n",
    "    continue\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
