{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas\n",
    "\n",
    "- Cual es el numero de tarea? The doc says proyecto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read *everything* before sending over; \"argumente brevemente sobre ello\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto 1 - Luis Eduardo Robles Jimenez\n",
    "\n",
    "# Minería de Texto para Turismo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TouristSpot:\n",
    "    def __init__(self, path, vocabSize = None):\n",
    "        self.reviews = pd.read_csv(path)\n",
    "        self.spotName = path.split('/')[-1][: -4]\n",
    "        self.vocabSize = vocabSize\n",
    "        self._cleanUp()\n",
    "        self.nDashes = 30\n",
    "\n",
    "    def _cleanUp(self):\n",
    "        columns = [\"Título de la opinión\", \"Opinión\"]\n",
    "        for col in columns:\n",
    "            desc = []\n",
    "            for o in self.reviews.loc[:, col]:\n",
    "                if o[0] == '\"': o = o[1:]\n",
    "                if o[-1] == '\"': o = o[:-1]\n",
    "                desc.append(o)\n",
    "            self.reviews.loc[:, col] = desc\n",
    "\n",
    "        if self.vocabSize is not None:\n",
    "            corpus = ' '.join(self.reviews.loc[:, \"Opinión\"])\n",
    "            self.vocabulary = FreqDist(word_tokenize(corpus)).most_common(self.vocabSize)\n",
    "            self.vocabulary = [word for word, _ in self.vocabulary]\n",
    "\n",
    "            def useTopWords(text):\n",
    "                words = word_tokenize(text)\n",
    "                return ' '.join([word if word in self.vocabulary else '<unk>' for word in words])\n",
    "            \n",
    "            self.reviews[\"Opinión\"] = self.reviews[\"Opinión\"].apply(useTopWords)\n",
    "\n",
    "    def topKwordcloud(self, k = 50):\n",
    "        vectorizer = TfidfVectorizer(min_df = 1, stop_words = ['spanish', 'english'])\n",
    "        bow = vectorizer.fit_transform(self.reviews[\"Opinión\"])\n",
    "        words = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        feats = SelectKBest(chi2, k = k)\n",
    "        feats.fit(bow, self.reviews['Escala'])\n",
    "        best = feats.get_support(indices = True)\n",
    "        words = ' '.join(words[best])\n",
    "\n",
    "        wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=3).generate(words)\n",
    "\n",
    "        print(f\"{'-' * self.nDashes} {self.spotName} {'-' * self.nDashes}\")\n",
    "\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout(pad=0)\n",
    "        plt.show()\n",
    "\n",
    "    def LSA(self):\n",
    "        print(f'{\"-\" * self.nDashes} {self.spotName} {\"-\" * self.nDashes}')\n",
    "        \n",
    "        subgroups = {}\n",
    "        subgroups['Hombres'] = self.reviews.loc[self.reviews.loc[:, 'Género'] == 'Masculino']\n",
    "        subgroups['Mujeres'] = self.reviews.loc[self.reviews.loc[:, 'Género'] == 'Femenino']\n",
    "        subgroups['Turistas Nacionales'] = self.reviews.loc[self.reviews.loc[:, 'Nacional ó Internacional'] == 'Nacional']\n",
    "        subgroups['Turistas Internacionales'] = self.reviews.loc[self.reviews.loc[:, 'Nacional ó Internacional'] == 'Internacional']\n",
    "        subgroups['Jovenes (10, 30)'] = self.reviews.loc[np.logical_and(self.reviews.loc[:, 'Edad'] > 0, self.reviews.loc[:, 'Edad'] < 30)]\n",
    "        subgroups['Mayores (60, 100)'] = self.reviews.loc[np.logical_and(self.reviews.loc[:, 'Edad'] > 60, self.reviews.loc[:, 'Edad'] < 100)]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(min_df = 1, stop_words = ['spanish', 'english'])\n",
    "        for sName in subgroups:\n",
    "            s = subgroups[sName]\n",
    "            print(f'Subgroup: {sName}')\n",
    "            bow = vectorizer.fit_transform(s.loc[:, 'Opinión'])\n",
    "            bow = preprocessing.normalize(bow, norm = 'l2')\n",
    "            dictionary = vectorizer.get_feature_names_out()\n",
    "            svd = TruncatedSVD(n_components = 3)\n",
    "            lsa = svd.fit_transform(bow)\n",
    "\n",
    "            for comp in svd.components_:\n",
    "                sortedComp = np.argsort(np.abs(comp))[::-1]\n",
    "                comp = comp[sortedComp]\n",
    "                dictionary = dictionary[sortedComp]\n",
    "                for term in dictionary[:10]: print(f'{term}', end = \" \")\n",
    "                print()\n",
    "            print()\n",
    "\n",
    "    def temporalAnalysis(self):\n",
    "\n",
    "        self.reviews['newDate'] = ['/'.join(date.split('/')[1:]) for date in self.reviews.loc[:, 'Fecha']]\n",
    "\n",
    "        dates = []\n",
    "        bad, neutral, good, total = [], [], [], []\n",
    "        for groupName, reviewsGroup in self.reviews.groupby('newDate'):\n",
    "            dates.append(groupName)\n",
    "            bad.append(np.sum(reviewsGroup.loc[:, 'Escala'] < 3))\n",
    "            neutral.append(np.sum(reviewsGroup.loc[:, 'Escala'] == 3))\n",
    "            good.append(np.sum(reviewsGroup.loc[:, 'Escala'] > 3))\n",
    "\n",
    "        grades = np.array(bad) + np.array(neutral) + np.array(good)\n",
    "        bad =       np.array(bad)       / grades * 100\n",
    "        neutral =   np.array(neutral)   / grades * 100\n",
    "        good =      np.array(good)      / grades * 100\n",
    "\n",
    "        argsort = np.argsort([datetime.strptime(date, '%m/%y' if len(date) == 5 else '%m/%Y') for date in dates])[::-1]\n",
    "        dates =     np.array([dates[i] for i in argsort])\n",
    "        bad =       np.array([bad[i] for i in argsort])\n",
    "        neutral =   np.array([neutral[i] for i in argsort])\n",
    "        good =      np.array([good[i] for i in argsort])\n",
    "\n",
    "\n",
    "        _, stackedChart = plt.subplots(figsize = (15, 15))\n",
    "        stackedChart.barh(dates, good, label='Good reviews', color = '#00ff00')\n",
    "        stackedChart.barh(dates, neutral, left = good, label='Neutral reviews', color = '#ffff00')\n",
    "        stackedChart.barh(dates, bad, left = good + neutral, label='Bad reviews', color = '#ff0000')\n",
    "        stackedChart.legend()\n",
    "        stackedChart.set_title(f'Reviews of {self.spotName} by month')\n",
    "        plt.show()\n",
    "\n",
    "    def describe(self):\n",
    "        nRows, nCols = 2, 1\n",
    "        fig = plt.figure(figsize = (15, 10))\n",
    "        fig.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "        print(self.nDashes * '-', self.spotName, self.nDashes * '-')\n",
    "\n",
    "        grades = fig.add_subplot(321)\n",
    "        avg = np.round(np.average(self.reviews.loc[:, 'Escala']), decimals = 2)\n",
    "        sd = np.round(np.std(self.reviews.loc[:, 'Escala']), decimals = 2)\n",
    "        grades.hist(self.reviews.loc[:, 'Escala'])\n",
    "        grades.set_title(f\"Grades (1 worst; 5 best); Average = {avg}; SD = {sd}\")\n",
    "\n",
    "        length = fig.add_subplot(322)\n",
    "        lenOpinions = [len(word_tokenize(o)) for o in self.reviews.loc[:, 'Opinión']]\n",
    "        avg = np.round(np.average(lenOpinions), decimals = 2)\n",
    "        sd = np.round(np.std(lenOpinions), decimals = 2)\n",
    "        length.hist(lenOpinions)\n",
    "        length.set_title(f\"Length of opinions (words); Average = {avg}; SD = {sd}\")\n",
    "\n",
    "        ages = fig.add_subplot(323)\n",
    "        ages.hist(self.reviews.loc[:, 'Edad'], bins = 10)\n",
    "        ages.set_title(f'Ages distribution')\n",
    "\n",
    "        visitors = fig.add_subplot(324)\n",
    "        visitors.hist(self.reviews.loc[:, 'Nacional ó Internacional'])\n",
    "        visitors.set_title('Local or foreigner')\n",
    "\n",
    "        monthNames = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        popularity = fig.add_subplot(325)\n",
    "        months = [int(d.split('/')[1]) for d in self.reviews.loc[:, 'Fecha']]\n",
    "        m, c = np.unique(months, return_counts = True)\n",
    "        popularity.bar(m, c)\n",
    "        popularity.set_title('Popularity by month')\n",
    "        popularity.set_xticks(np.arange(1, len(m) + 1), labels = monthNames)\n",
    "\n",
    "        languages = fig.add_subplot(326)\n",
    "        m, c = np.unique(self.reviews.loc[:, 'Idioma'], return_counts = True)\n",
    "        languages.barh(m, c)\n",
    "        languages.set_title('Language')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividades\n",
    "\n",
    "### 1. Preprocesamiento y stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/guanajuato/\"\n",
    "#spots = [TouristSpot(os.path.join(path, d), vocabSize = 10000) for d in os.listdir(path)]\n",
    "spots = [TouristSpot(os.path.join(path, d), vocabSize = None) for d in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.describe()\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.topKwordcloud()\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.LSA()\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.temporalAnalysis()\n",
    "    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
