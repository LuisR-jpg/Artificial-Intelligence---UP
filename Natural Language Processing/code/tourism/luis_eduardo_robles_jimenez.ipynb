{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preguntas\n",
    "\n",
    "- Cual es el numero de tarea? The doc says proyecto 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntext = \"Hola como estas, jajajaja, que haces?\"\\ntext = \"The quick brown fox jumps over the lazy dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog \"\\n\\nwordcloud = WordCloud(width=800, height=800, background_color=\\'white\\', min_font_size=3).generate(text)\\n\\nplt.figure(figsize=(8,8))\\nplt.imshow(wordcloud)\\nplt.axis(\"off\")\\nplt.tight_layout(pad=0)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "text = \"Hola como estas, jajajaja, que haces?\"\n",
    "text = \"The quick brown fox jumps over the lazy dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog dog \"\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=800, background_color='white', min_font_size=3).generate(text)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proyecto 1 - Luis Eduardo Robles Jimenez\n",
    "\n",
    "# Minería de Texto para Turismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TouristSpot:\n",
    "    def __init__(self, path):\n",
    "        self.reviews = pd.read_csv(path)\n",
    "        self.spotName = path.split('/')[-1][: -4]\n",
    "        self._cleanUp()\n",
    "        self.nDashes = 30\n",
    "\n",
    "    def _cleanUp(self):\n",
    "        columns = [\"Título de la opinión\", \"Opinión\"]\n",
    "        for col in columns:\n",
    "            desc = []\n",
    "            for o in self.reviews.loc[:, col]:\n",
    "                if o[0] == '\"': o = o[1:]\n",
    "                if o[-1] == '\"': o = o[:-1]\n",
    "                desc.append(o)\n",
    "            self.reviews.loc[:, col] = desc\n",
    "\n",
    "    def wordCloud(self):\n",
    "        #pip install wordcloud\n",
    "        pass\n",
    "\n",
    "    def LSA(self):\n",
    "        print(f'{\"-\" * self.nDashes} {self.spotName} {\"-\" * self.nDashes}')\n",
    "        \n",
    "        subgroups = {}\n",
    "        subgroups['Hombres'] = self.reviews.loc[self.reviews.loc[:, 'Género'] == 'Masculino']\n",
    "        subgroups['Mujeres'] = self.reviews.loc[self.reviews.loc[:, 'Género'] == 'Femenino']\n",
    "        subgroups['Turistas Nacionales'] = self.reviews.loc[self.reviews.loc[:, 'Nacional ó Internacional'] == 'Nacional']\n",
    "        subgroups['Turistas Internacionales'] = self.reviews.loc[self.reviews.loc[:, 'Nacional ó Internacional'] == 'Internacional']\n",
    "        subgroups['Jovenes (10, 30)'] = self.reviews.loc[np.logical_and(self.reviews.loc[:, 'Edad'] > 0, self.reviews.loc[:, 'Edad'] < 30)]\n",
    "        subgroups['Mayores (60, 100)'] = self.reviews.loc[np.logical_and(self.reviews.loc[:, 'Edad'] > 60, self.reviews.loc[:, 'Edad'] < 100)]\n",
    "\n",
    "        vectorizer = TfidfVectorizer(min_df = 1, stop_words = ['spanish', 'english'])\n",
    "        for sName in subgroups:\n",
    "            s = subgroups[sName]\n",
    "            print(f'Subgroup: {sName}')\n",
    "            bow = vectorizer.fit_transform(s.loc[:, 'Opinión'])\n",
    "            bow = preprocessing.normalize(bow, norm = 'l2')\n",
    "            dictionary = vectorizer.get_feature_names_out()\n",
    "            svd = TruncatedSVD(n_components = 3)\n",
    "            lsa = svd.fit_transform(bow)\n",
    "\n",
    "            for comp in svd.components_:\n",
    "                sortedComp = np.argsort(np.abs(comp))[::-1]\n",
    "                comp = comp[sortedComp]\n",
    "                dictionary = dictionary[sortedComp]\n",
    "                for term in dictionary[:10]: print(f'{term}', end = \" \")\n",
    "                print()\n",
    "            print()\n",
    "\n",
    "    def temporalAnalysis(self):\n",
    "\n",
    "        self.reviews['newDate'] = ['/'.join(date.split('/')[1:]) for date in self.reviews.loc[:, 'Fecha']]\n",
    "\n",
    "        dates = []\n",
    "        bad, neutral, good, total = [], [], [], []\n",
    "        for groupName, reviewsGroup in self.reviews.groupby('newDate'):\n",
    "            dates.append(groupName)\n",
    "            bad.append(np.sum(reviewsGroup.loc[:, 'Escala'] < 3))\n",
    "            neutral.append(np.sum(reviewsGroup.loc[:, 'Escala'] == 3))\n",
    "            good.append(np.sum(reviewsGroup.loc[:, 'Escala'] > 3))\n",
    "\n",
    "        grades = np.array(bad) + np.array(neutral) + np.array(good)\n",
    "        bad =       np.array(bad)       / grades * 100\n",
    "        neutral =   np.array(neutral)   / grades * 100\n",
    "        good =      np.array(good)      / grades * 100\n",
    "\n",
    "        argsort = np.argsort([datetime.strptime(date, '%m/%y' if len(date) == 5 else '%m/%Y') for date in dates])[::-1]\n",
    "        dates =     np.array([dates[i] for i in argsort])\n",
    "        bad =       np.array([bad[i] for i in argsort])\n",
    "        neutral =   np.array([neutral[i] for i in argsort])\n",
    "        good =      np.array([good[i] for i in argsort])\n",
    "\n",
    "\n",
    "        _, stackedChart = plt.subplots(figsize = (15, 15))\n",
    "        stackedChart.barh(dates, good, label='Good reviews', color = '#00ff00')\n",
    "        stackedChart.barh(dates, neutral, left = good, label='Neutral reviews', color = '#ffff00')\n",
    "        stackedChart.barh(dates, bad, left = good + neutral, label='Bad reviews', color = '#ff0000')\n",
    "        stackedChart.legend()\n",
    "        stackedChart.set_title(f'Reviews of {self.spotName} by month')\n",
    "        plt.show()\n",
    "\n",
    "    def describe(self):\n",
    "        nRows, nCols = 2, 1\n",
    "        fig = plt.figure(figsize = (15, 10))\n",
    "        fig.subplots_adjust(hspace = 0.5)\n",
    "\n",
    "        print(self.nDashes * '-', self.spotName, self.nDashes * '-')\n",
    "\n",
    "        grades = fig.add_subplot(321)\n",
    "        avg = np.round(np.average(self.reviews.loc[:, 'Escala']), decimals = 2)\n",
    "        sd = np.round(np.std(self.reviews.loc[:, 'Escala']), decimals = 2)\n",
    "        grades.hist(self.reviews.loc[:, 'Escala'])\n",
    "        grades.set_title(f\"Grades (1 worst; 5 best); Average = {avg}; SD = {sd}\")\n",
    "\n",
    "        length = fig.add_subplot(322)\n",
    "        lenOpinions = [len(TweetTokenizer().tokenize(o)) for o in self.reviews.loc[:, 'Opinión']]\n",
    "        avg = np.round(np.average(lenOpinions), decimals = 2)\n",
    "        sd = np.round(np.std(lenOpinions), decimals = 2)\n",
    "        length.hist(lenOpinions)\n",
    "        length.set_title(f\"Length of opinions (words); Average = {avg}; SD = {sd}\")\n",
    "\n",
    "        ages = fig.add_subplot(323)\n",
    "        ages.hist(self.reviews.loc[:, 'Edad'], bins = 10)\n",
    "        ages.set_title(f'Ages distribution')\n",
    "\n",
    "        visitors = fig.add_subplot(324)\n",
    "        visitors.hist(self.reviews.loc[:, 'Nacional ó Internacional'])\n",
    "        visitors.set_title('Local or foreigner')\n",
    "\n",
    "        monthNames = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        popularity = fig.add_subplot(325)\n",
    "        months = [int(d.split('/')[1]) for d in self.reviews.loc[:, 'Fecha']]\n",
    "        m, c = np.unique(months, return_counts = True)\n",
    "        popularity.bar(m, c)\n",
    "        popularity.set_title('Popularity by month')\n",
    "        popularity.set_xticks(np.arange(1, len(m) + 1), labels = monthNames)\n",
    "\n",
    "        languages = fig.add_subplot(326)\n",
    "        m, c = np.unique(self.reviews.loc[:, 'Idioma'], return_counts = True)\n",
    "        languages.barh(m, c)\n",
    "        languages.set_title('Language')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actividades\n",
    "\n",
    "### 1. Preprocesamiento y stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../data/guanajuato/\"\n",
    "spots = [TouristSpot(os.path.join(path, d)) for d in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.describe()\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.temporalAnalysis()\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spot in spots: \n",
    "    break\n",
    "    spot.LSA()\n",
    "    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
