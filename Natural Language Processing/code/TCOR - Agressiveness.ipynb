{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCOR\n",
    "\n",
    "Term Co-ocurrence representation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "$$\n",
    "w_{k, j} = tff(t_k, t_j) log(\\frac{|T|}{T_k})\n",
    "$$\n",
    "\n",
    "$$\n",
    "tff(t_k, t_j) = \n",
    "\\begin{cases}\n",
    "1 + log(\\#(t_k, t_j)) &\\quad if \\ \\#(t_k, t_j) > 0 \\\\\n",
    "0 &\\quad otherwise\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $T_k$ is the number of terms the k-th word co-occured with\n",
    "- $|T|$ is the size of the vocabulary\n",
    "- $\\#(t_k, t_j)$ is the number of documents where $t_k$ co-occured with $t_j$\n",
    "- $t$ is a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts_from_file(path_corpus, path_truth):\n",
    "    txt = []\n",
    "    y = []\n",
    "    with open(path_corpus, \"r\") as f_corpus, open(path_truth, \"r\") as f_truth:\n",
    "        for tuit in f_corpus:\n",
    "            txt += [tuit]\n",
    "        for label in f_truth:\n",
    "            y += [label] \n",
    "    return txt, list(map(int, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCOR(tweets, V, dict_indices):\n",
    "    def tff(tk, tj = None): # If one argument: return the number of words tk co-occurs with; if two, return the number of times they co-occur\n",
    "        pass\n",
    "    tcor = torch.zeros(len(V), len(V))\n",
    "    for ik, k in enumerate(V):\n",
    "        for ij, j in enumerate(V):\n",
    "            #if ij == ik: continue\n",
    "            tcor[ik, ij] = tff(tk, tj) * torch.log(len(V) / tff(tk))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_txt, tr_y = get_texts_from_file(\"../data/agresividad/mex_train.txt\", \"../data/agresividad/mex_train_labels.txt\")\n",
    "val_txt, val_y = get_texts_from_file(\"../data/agresividad/mex_val.txt\", \"../data/agresividad/mex_val_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_palabras = []\n",
    "corpus_tweets = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for doc in tr_txt:\n",
    "    corpus_palabras += tokenizer.tokenize(doc) # A single list\n",
    "    corpus_tweets += [tokenizer.tokenize(doc)] # Several lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3383, 'que'), (3357, 'de'), (2774, '.')]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000\n",
    "fdist = nltk.FreqDist(corpus_palabras)\n",
    "vocab = sorted([(fdist[key], key) for key in fdist])[:: -1][: vocab_size]\n",
    "print(vocab[: 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['que', 'de', '.', 'a', 'la', 'y', 'no', 'me', '!', 'el']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = dict()\n",
    "for i, w in enumerate(vocab):\n",
    "    _, word = w\n",
    "    indices[word] = i\n",
    "print(len(indices))\n",
    "list(indices)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m TCOR_tr \u001b[39m=\u001b[39m TCOR(tr_txt, vocab, indices)\n\u001b[0;32m      2\u001b[0m TCOR_val \u001b[39m=\u001b[39m TCOR(val_txt, vocab, indices)\n\u001b[1;32m----> 3\u001b[0m TCOR_tr\u001b[39m.\u001b[39;49mshape\n\u001b[0;32m      4\u001b[0m TCOR_tr\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "TCOR_tr = TCOR(tr_txt, vocab, indices)\n",
    "TCOR_val = TCOR(val_txt, vocab, indices)\n",
    "TCOR_tr.shape\n",
    "TCOR_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'concordance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m corpus_palabras\u001b[39m.\u001b[39;49mconcordance(\u001b[39m\"\u001b[39m\u001b[39mhola\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'concordance'"
     ]
    }
   ],
   "source": [
    "corpus_palabras.concordance(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text\n",
    "corpus = Text(corpus_palabras)\n",
    "corpusT = Text(corpus_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 14 of 14 matches:\n",
      ".. pontela poca madre ! ! ! @usuario hola to√±o ayer en tu programa como a las \n",
      "manda su rica verga üòç üòú üòù üòù @usuario hola pinche toluca . te pones bien fr√≠a h\n",
      "oger peor d√≠a pa chingar la momi . - hola pinche putita te quedaste sin mundia\n",
      "mi prima la luchona . ella me dice \" hola \" y yo le contest√≥ algo como \" hola \n",
      " hola \" y yo le contest√≥ algo como \" hola prieta que quiere ser g√ºera \" venimo\n",
      "as trabajan en el metro ! no mamar . hola pinche putita as√≠ que te gustan gran\n",
      "a que los pario ooohhhooo oooohhoooo hola pinche putito te pones bien cachondo\n",
      "r chupar y con la punta de mi lengua hola que bonito que por una parte ya te v\n",
      "ue tu eres el del video que dice : \" hola pinche putita \" me quejar√© toda la v\n",
      "fue como hilo de media . mea culpa . hola tenia tiempo que no me conectaba . p\n",
      " ! depende de ustedes beb√©s @usuario hola a cual funcionario del gob del edome\n",
      "√≥ mal ‚Ä¶ la neta el coral blanco y el hola pinche putita cachonda han sido lo m\n",
      "cada loca que se tienen que bancar üò≠ hola . enviamos a subcontratista cuando e\n",
      " putas gatas haciendo de las suyas . hola pam cuando me vas a dar las nalgas y\n"
     ]
    }
   ],
   "source": [
    "corpus.concordance('hola')\n",
    "corpusT.concordance('hola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@usuario @usuario; puta madre; los putos; las putas; vale verga; todos\n",
      "los; por qu√©; mam√° luchona; sus putas; todas las; poca madre; putas\n",
      "madres; mil putas; las mujeres; valer verga; esos putos; estoy hasta;\n",
      "estoy loca; otra vez; creo que\n"
     ]
    }
   ],
   "source": [
    "corpus.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..._ver ._que que_otro \"_que ._joto\n"
     ]
    }
   ],
   "source": [
    "corpus.common_contexts(['a', 'el'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConcordanceLine(left=['conveniente', 'seria', 'que', 'lo', 'retes', 'a', 'unos', 'vergazos', 'mi', 'jelipe', '!', 'r√≥mpele', 'la', 'madre', 'a', 'ese', 'pinchi', 'joto', '!'], query='el', right=['marica', 'de', 'mi', 'ex', 'me', 'tiene', 'bloqueada', 'de', 'todo', 'as√≠', 'uno', 'no', 'puede', 'admirar', 'la', '\"', 'belleza', '\"'], offset=68, left_print=' r√≥mpele la madre a ese pinchi joto !', right_print='marica de mi ex me tiene bloqueada de', line=' r√≥mpele la madre a ese pinchi joto ! el marica de mi ex me tiene bloqueada de'),\n",
       " ConcordanceLine(left=['no', 'mejoran', '!', '!', '@usuario', '@usuario', 'y', 'si', 'este', '#hermano', '#hdp', '@usuario', 'tuyo', ';', 'se', 'queda', 'en', '#panam√°', '?'], query='el', right=['üê∑', 'd', '#javidu', 'sonre√≠a', 'en', '#guatemala', 'estar√≠a', 'mejor', 'all√°', 'porque', 'lo', 'primero', 'que', 'busco', 'en', 'una', 'cuenta', 'es'], offset=339, left_print='@usuario tuyo ; se queda en #panam√° ?', right_print='üê∑ d #javidu sonre√≠a en #guatemala est', line='@usuario tuyo ; se queda en #panam√° ? el üê∑ d #javidu sonre√≠a en #guatemala est'),\n",
       " ConcordanceLine(left=['imposible', 'dejar', 'de', 'mirarte', 'y', 'de', 'contemplarte', 'mi', 'loca', 'pasi√≥n', '...', 'ay', 'amigxs', 'la', 'tristeza', 'invade', 'nuestros', 'corazones', 'es'], query='el', right=['cinco', 'pero', 'de', 'octubre', 'a', 'la', 'puta', 'verga', '.', 'üòû', 'üòû', 'üòû', 'üíî', '(', 'jajajajaja', 'que', 'pendeja', 'la'], offset=431, left_print='tristeza invade nuestros corazones es', right_print='cinco pero de octubre a la puta verga', line='tristeza invade nuestros corazones es el cinco pero de octubre a la puta verga'),\n",
       " ConcordanceLine(left=['a', 'ti', 't', 'da', 'pena', 'mostrar', 'tu', 'foto', 'por', 'tu', 'cara', 'de', 'estupido', 'y', 'maricon', 'que', 'tienes', 've', 'con'], query='el', right=['america', 'a', 'chingar', 'a', 'su', 'madre', '@usuario', 'luchona', 'buchona', 'mamona', 'y', 'sangrona', 'y', 'copiona', 'el', 'hijo', 'de', 'la'], offset=559, left_print=' estupido y maricon que tienes ve con', right_print='america a chingar a su madre @usuario', line=' estupido y maricon que tienes ve con el america a chingar a su madre @usuario'),\n",
       " ConcordanceLine(left=['que', 'tienes', 've', 'con', 'el', 'america', 'a', 'chingar', 'a', 'su', 'madre', '@usuario', 'luchona', 'buchona', 'mamona', 'y', 'sangrona', 'y', 'copiona'], query='el', right=['hijo', 'de', 'la', 'jefa', 'de', 'mi', 'mam√°', 'est√°', 'bien', 'guapo', '.', 'pero', 'tiene', '16', ':(', 'y', 'una', 'novia'], offset=574, left_print='a buchona mamona y sangrona y copiona', right_print='hijo de la jefa de mi mam√° est√° bien ', line='a buchona mamona y sangrona y copiona el hijo de la jefa de mi mam√° est√° bien '),\n",
       " ConcordanceLine(left=['una', 'novia', '.', 'porqu√©', 'me', 'haces', 'esto', 'diosito', '@usuario', '@usuario', 'yo', 'le', 'dec√≠a', 'a', 'marquitos', 'pero', 'pues', 'te', 'pones'], query='el', right=['saco', 'marica', 'awebo', 'putos', 'el', 'se√±or', 'zhang', 'ya', 'me', 'dio', 'regalo', 'en', 'clase', 'de', 'asia', 'y', 'tal', 'vez'], offset=610, left_print=' dec√≠a a marquitos pero pues te pones', right_print='saco marica awebo putos el se√±or zhan', line=' dec√≠a a marquitos pero pues te pones el saco marica awebo putos el se√±or zhan'),\n",
       " ConcordanceLine(left=['haces', 'esto', 'diosito', '@usuario', '@usuario', 'yo', 'le', 'dec√≠a', 'a', 'marquitos', 'pero', 'pues', 'te', 'pones', 'el', 'saco', 'marica', 'awebo', 'putos'], query='el', right=['se√±or', 'zhang', 'ya', 'me', 'dio', 'regalo', 'en', 'clase', 'de', 'asia', 'y', 'tal', 'vez', 'si', 'no', 'estuvieras', 'tan', 'violado'], offset=615, left_print='s te pones el saco marica awebo putos', right_print='se√±or zhang ya me dio regalo en clase', line='s te pones el saco marica awebo putos el se√±or zhang ya me dio regalo en clase'),\n",
       " ConcordanceLine(left=['la', 'existencia', 'si', 'es', 'guapa', 'o', 'no', 'al', 'final', 'vale', 'verga', '.', 'pendejos', 'pero', 'q', 'tal', 'si', 'huviera', 'perdido'], query='el', right=['puto', 'dl', 'puebla', 'pinchi', 'equipo', 'mediocre', '@usuario', 'que', 'nuestro', 'se√±or', 'jesus', 'lo', 'cuide', 'y', 'proteja', 'y', 'nuestra', 'madre'], offset=696, left_print='endejos pero q tal si huviera perdido', right_print='puto dl puebla pinchi equipo mediocre', line='endejos pero q tal si huviera perdido el puto dl puebla pinchi equipo mediocre'),\n",
       " ConcordanceLine(left=['defienden', 'mejor', 'que', 't√∫', '.', 'll√©gale', 'a', 'la', 'verga', 'pinche', 'pu√±etas', '.', 'solo', 'espero', 'que', 'hoy', 'no', 'me', 'toque'], query='el', right=['mismo', '#traficogt', 'ee', 'todas', 'las', 'putas', 'ma√±anas', 'pinche', 'mono', 'maricon', 'muy', 'chingon', 'haciendo', 'llorar', 'a', 'una', 'se√±ora', 'mayor'], offset=763, left_print='tas . solo espero que hoy no me toque', right_print='mismo #traficogt ee todas las putas m', line='tas . solo espero que hoy no me toque el mismo #traficogt ee todas las putas m'),\n",
       " ConcordanceLine(left=['tener', 'madre', 'ojete', '!', '!', '!', 'putos', 'simios', 'ojal√°', 'no', 'lleguen', 'al', 'mundial', 'malditos', 'hondure√±os', 'miserables', '.', 'che', 'si'], query='el', right=['relator', 'es', 'de', 'allboys', 'ponganlo', 'a', 'relatar', 'a', 'los', 'putos', 'de', 'floresta', '!', 'tremendo', 'culo', 'ardido', 'el', 'hijo'], offset=804, left_print='lditos hondure√±os miserables . che si', right_print='relator es de allboys ponganlo a rela', line='lditos hondure√±os miserables . che si el relator es de allboys ponganlo a rela')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.concordance_list(['el'], lines = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyTorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5894844b2d2ed0dfa0303dd3da765415d62adce6c74979413b2b103f5e23799"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
